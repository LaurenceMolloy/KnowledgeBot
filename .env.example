###### SLACK Environment Settings (our #KNOWLEDGE source)
# NOTE: KnowledgeBot must be a member of the Slack channels identified below
SLACK_TOKEN = "REPLACE_WITH_YOUR_SLACK_BOT_TOKEN"

SLACK_KNOWLEDGE_CHANNELS = "EXAMPLE_1,EXAMPLE_2" # channels that include exportable #KNOWLEDGE (a comma-separated string)
SLACK_CHANNEL_TYPES = "public_channel"           # channel types include: public_channel, private_channel, im, mpim
SLACK_EDIT_CHANNEL = "EXAMPLE_3"                 # #EDIT messages channel, pointing at messages containing #KNOWLEDGE for re-processing

BOT_EMOJI = "mortar_board"                # emoji used to mark #KNOWLEDGE and #EDIT messages processed by the bot

###### LLM Environment Settings (for enriching #KNOWLEDGE with tags and a brief summary)
# NOTE: currently, only local Ollama servers have been tested - testing of remote servers is still a TODO
ENABLE_LLM = 'false'
LLM_SERVER = 'localhost'
LLM_PORT = 443
LLM_PROVIDER = "ollama"                 # supported values: ('ollama', 'null'). null => skip LLM enhancement
LLM_MODEL = "mistral:7b-instruct-q4_0"  # must be an available model on the ollama server

###### General Environment Settings
EXPORT_FOLDER = "./data"    # destination for extracted and annotated #KNOWLEDGE
STATE_FILE = "./state.json" # for persisting the last run time between each #KNOWLEDGE extraction run
                            # (for efficiency, KnowledgeBot only processes NEW Slack messages since last run)